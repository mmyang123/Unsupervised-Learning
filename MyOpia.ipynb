{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee7fd7db",
   "metadata": {},
   "source": [
    "# Homework 20: Unsupervised Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fba8f3",
   "metadata": {},
   "source": [
    "## Step 1: Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d8eca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e82d79",
   "metadata": {},
   "source": [
    "###  Step 1: Load the MyOpia dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ed67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the preprocessed MyOpia CSV file\n",
    "file_path = Path(\"Resource/myopia.csv\")\n",
    "df_myopia = pd.read_csv(file_path)\n",
    "df_myopia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0373b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names\n",
    "df_myopia.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea18962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There were 81 myopica (1) children samples and 537 (0) non-myopic children samples\n",
    "\n",
    "df_myopia[\"MYOPIC\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f32770",
   "metadata": {},
   "source": [
    "#### Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffeb3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into data and target\n",
    "\n",
    "y = df_myopia[\"MYOPIC\"].values\n",
    "X = df_myopia.drop(\"MYOPIC\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea040ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into two groups, the training and test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f08638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scaler to standardize the data, this is the default scaler to use.\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba663fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the X_train data to the standard scaler\n",
    "\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a85c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X_train and X_test data\n",
    "# Note that the scaler used to transform X_train and X_test was trained on X_train set\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b0a39",
   "metadata": {},
   "source": [
    "### Create predictions with KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc31ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate KNN model and make predictions, KNN use odd values only, not even values.\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred = knn.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a67315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22de31b2",
   "metadata": {},
   "source": [
    "## Step 2: Perform Dimensionality Reduction with PCA\n",
    "One good thing about using dimensionality reduction is it's techniques in which it can help to speed up machine learning by reducing the size of large datasets, while preserving most of the useful information that needed to better fit a predictive model.\n",
    "\n",
    "Principal Component Analysis (PCA) happens to be one of the dimensionality reduction techniques that I will use for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d290e1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do this on Windows machine before importing Kmeans to avoid a known bug (memory leak).\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ea2b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PCA model\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Get two principa components for the data\n",
    "myopia = pca.fit_transform(df_myopia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896cf97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform PCA data to a DataFrame\n",
    "df_myopia_pca = pd.DataFrame(\n",
    "    data=myopia, columns=[\"principal component 1\", \"principal component 2\"]\n",
    ")\n",
    "df_myopia_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6944488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the explained variance\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd9a040",
   "metadata": {},
   "source": [
    "### Sample Analysis\n",
    "According to the explained variance, the first principal component contains approximately 73% of the variance and the second principal component contains 16% of the variance. We have approximately 89% of the information in the original dataset, and we will see whether increasing the number of principal components to 3 will increase the explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a17e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PCA model for 3 principal components\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "# Get two principal components for the iris data.\n",
    "myopia_pca = pca.fit_transform(df_myopia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform PCA data to a DataFrame\n",
    "df_myopia_pca = pd.DataFrame(\n",
    "    data=myopia_pca,\n",
    "    columns=[\"principal component 1\", \"principal component 2\", \"principal component 3\"],\n",
    ")\n",
    "df_myopia_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9892a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the explained variance\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a31e666",
   "metadata": {},
   "source": [
    "### Sample Analysis\n",
    "The first principal component has 73%, the second principal component has 16%, and the third principal component has 1%, an overall total of 90% for the increased variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fedd0f0",
   "metadata": {},
   "source": [
    "## Step 3: Perform a Cluster Analysis with K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5806e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the K-means with K = 3\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=3, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca02e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(df_myopia_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c0914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "predictions = model.predict(df_myopia_pca)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81352cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new class column to df_myopia\n",
    "df_myopia[\"class\"] = model.labels_\n",
    "df_myopia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df_myopia.copy()\n",
    "new_df['cluster'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb58598",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3546720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the K-means model\n",
    "model = KMeans(n_clusters=3, random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(df_myopia_pca)\n",
    "\n",
    "# Predict clusters\n",
    "predictions = model.predict(df_myopia_pca)\n",
    "\n",
    "# Add the predicted class columns\n",
    "# df_myopia_pca[\"class\"] = model.labels_\n",
    "# df_myopia_pca.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f1f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd08575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 3 clusters of random data\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "data, _ = make_blobs(n_samples=300, centers=3,\n",
    "                    cluster_std=0.60, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dae868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "plt.scatter(data[:, 0], data[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2611df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use n_clusters=4 as te k value\n",
    "# We can see from the plot above that there are 4 clusters\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "\n",
    "# Fit the model to the data\n",
    "kmeans.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a402a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the clusters\n",
    "predicted_clusters = kmeans.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0218b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predicted clusters to see if the model predicted the correct clusters\n",
    "# This is visual validation that the model was trained correctly.\n",
    "\n",
    "plt.scatter(data[:, 0], data[:, 1], c=predicted_clusters, s=50, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73853624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce2113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "inertia = []\n",
    "# Same as k = list(range(1, 11))\n",
    "k = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "\n",
    "# Looking for the best k\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(df_myopia)\n",
    "    inertia.append(km.inertia_)\n",
    "\n",
    "# Define a DataFrame to plot the Elbow Curve using hvPlot\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "\n",
    "plt.plot(df_elbow['k'], df_elbow['inertia'])\n",
    "plt.xticks(range(1,11))\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb396f64",
   "metadata": {},
   "source": [
    "## Step 4: Make a Recommendation\n",
    "When we start at 1 cluster on x-axis, the inertia is at it's highest point. When we increased the k to 2 clusters the inertia decreased tremendously going downwards. But when we add the 3 clusters, the inertia remained to be a small drop and it gradually moved downwards on the increased k number of clusters.\n",
    "\n",
    "Therefore, I would say that the elbow of the curve marks the most difference is at the point of k-3 because anything else larger than k-3 shows a minimal change in the decreased of inertia, or the error of the model. \n",
    "\n",
    "Based on the findings, my recommendation is that these patients could be clustered into four groups. Because of the similarities in the different deminsions of because of the large dataset, K-means will assign the k-groups to each of the four clusters based on the distance from each group's centroid, or most clustered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb01fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
